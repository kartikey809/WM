{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "19BCE1327_WebMining_Lab3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "#importing libraries for stemming and tokenizing \n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "  \n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02igKwC1VJk6",
        "outputId": "8643d707-9cd8-4532-8174-f17e06fbee42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs0v0aqXRRNE"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "  \n",
        "# remove stopwords function\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = [ps.stem(word) for word in word_tokens if word not in stop_words]\n",
        "    return filtered_text\n",
        "d1_string = \"Selenium is a portable framework for testing web applications;\"\n",
        "d1 = re.sub(r'[^\\w\\s]', '', d1_string.lower())\n",
        "d2_string = \"Beautiful Soup is useful for web scraping with selenium\"\n",
        "d2 = re.sub(r'[^\\w\\s]', '', d2_string.lower())\n",
        "d3_string = \"It is a python package for parsing the pages using selenium\"\n",
        "d3 = re.sub(r'[^\\w\\s]', '', d3_string.lower())\n",
        "d4_string = \"Java programming can be used for web applications\"\n",
        "d4 = re.sub(r'[^\\w\\s]', '', d4_string.lower())\n",
        "d5_string = \"scraping web and crawling web is useful with selenium framework\" \n",
        "d5 = re.sub(r'[^\\w\\s]', '', d5_string.lower())\n",
        "Documents = [d1,d2,d3,d4,d5]  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doclist=[]\n",
        "strlist = []\n",
        "for ele in Documents:\n",
        "  strlist = ' '.join(remove_stopwords(ele))\n",
        "  doclist.append(strlist)\n",
        "print(doclist)   #preproceesed document content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tO7Kl9kE48F",
        "outputId": "b8c7c268-9d4c-4c50-f072-5d20df4011cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['selenium portabl framework test web applic', 'beauti soup use web scrape selenium', 'python packag pars page use selenium', 'java program use web applic', 'scrape web crawl web use selenium framework']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_occurence(text, word) :       #for frequeny of word and position in document\n",
        "    text = text.replace('/[^A-Za-z0-9]/g', '')\n",
        "    text = text.replace(' ', ' ')\n",
        "    text = text.lower()\n",
        "    text_words = text.strip().split()\n",
        "    word_count = 0\n",
        "    word_positions = []\n",
        "    for i in range(len(text_words)) :\n",
        "        if word == text_words[i] :\n",
        "            word_count += 1\n",
        "            word_positions.append(i)\n",
        "    return (word_count, word_positions)\n",
        "def tokenize_preprocessed_text(text):            #tokenizing preproceeses text in documents\n",
        "    s = text\n",
        "    words = word_tokenize(s)\n",
        "    return words\n",
        "    \n",
        "inv_index = {}   #inverted index dictionary\n",
        "for (i, doc) in enumerate(doclist) :\n",
        "    words = tokenize_preprocessed_text(doc)\n",
        "    for word in words :\n",
        "        if word not in inv_index :\n",
        "            inv_index[word] = []\n",
        "        frequency, occurence_pos_list = word_occurence(doc, word)\n",
        "        inv_index[word].append(((i+1), frequency, occurence_pos_list))  #Key - word\n",
        "                                                                         #Values - list of doc ids having freq  and list of positions in document\n",
        "\n",
        "print(\"_________________INVERTED INDEX STRUCTURE_________________\")\n",
        "for index in inv_index.items():\n",
        "    print(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3TD8tdeK6ft",
        "outputId": "b63bc605-e2d0-4e9e-d592-a9a708601457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_________________INVERTED INDEX STRUCTURE_________________\n",
            "('selenium', [(1, 1, [0]), (2, 1, [5]), (3, 1, [5]), (5, 1, [5])])\n",
            "('portabl', [(1, 1, [1])])\n",
            "('framework', [(1, 1, [2]), (5, 1, [6])])\n",
            "('test', [(1, 1, [3])])\n",
            "('web', [(1, 1, [4]), (2, 1, [3]), (4, 1, [3]), (5, 2, [1, 3]), (5, 2, [1, 3])])\n",
            "('applic', [(1, 1, [5]), (4, 1, [4])])\n",
            "('beauti', [(2, 1, [0])])\n",
            "('soup', [(2, 1, [1])])\n",
            "('use', [(2, 1, [2]), (3, 1, [4]), (4, 1, [2]), (5, 1, [4])])\n",
            "('scrape', [(2, 1, [4]), (5, 1, [0])])\n",
            "('python', [(3, 1, [0])])\n",
            "('packag', [(3, 1, [1])])\n",
            "('pars', [(3, 1, [2])])\n",
            "('page', [(3, 1, [3])])\n",
            "('java', [(4, 1, [0])])\n",
            "('program', [(4, 1, [1])])\n",
            "('crawl', [(5, 1, [2])])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 2\n",
        "\n",
        "Search the following words using  inverted index\n",
        "\n",
        "a. Selenium AND web"
      ],
      "metadata": {
        "id": "IuWqbID6xpAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Selenium AND web word occurs in the following position\")\n",
        "sel=[]\n",
        "first_tuple_elements_sel = [a_tuple[0] for a_tuple in inv_index.get(\"selenium\")]    #extracting doc ids from inverted index \n",
        "                                                                                    #dict value using get(keyword)\n",
        "for docid in first_tuple_elements_sel:\n",
        "  sel.append(docid)\n",
        "  \n",
        "web=[]\n",
        "first_tuple_elements_web = [a_tuple[0] for a_tuple in inv_index.get(\"web\")]\n",
        "for docid in first_tuple_elements_web:\n",
        "  web.append(docid)\n",
        "\n",
        "print(\"DOC IDs containing selenium and web are : \")\n",
        "def Intersection(sel, web):                                #for performing AND operation i.e. intersection\n",
        "    return set(sel).intersection(web)\n",
        "print(Intersection(sel, web))    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZLwZuIqSimu",
        "outputId": "83896be5-7c10-4481-fe60-315ddf4d516f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selenium AND web word occurs in the following position\n",
            "DOC IDs containing selenium and web are : \n",
            "{1, 2, 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###b. Selenium"
      ],
      "metadata": {
        "id": "sp2E60dwyTJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "first_tuple_elements = [a_tuple[0] for a_tuple in inv_index.get(\"selenium\")]\n",
        "print(\"DOC IDs containing selenium are : \")\n",
        "for docid in first_tuple_elements:\n",
        "  print(docid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZfnM9WLyNi1",
        "outputId": "092d5c73-c4b8-4c75-e6d3-9480e16b42c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DOC IDs containing selenium are : \n",
            "1\n",
            "2\n",
            "3\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###c. Python or java"
      ],
      "metadata": {
        "id": "LM6GnLED4_qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Python Or java word occurs in the following Doc Ids\")\n",
        "pyt=[]\n",
        "first_tuple_elements_python = [a_tuple[0] for a_tuple in inv_index.get(\"python\")]    #extracting doc ids from inverted index \n",
        "                                                                                    #dict value using get(keyword)\n",
        "\n",
        "for docid in first_tuple_elements_python:\n",
        "  pyt.append(docid)\n",
        "  \n",
        "jav=[]\n",
        "first_tuple_elements_java = [a_tuple[0] for a_tuple in inv_index.get(\"java\")]\n",
        "for docid in first_tuple_elements_java:\n",
        "  jav.append(docid)\n",
        "\n",
        "unique = list(set(pyt + jav))      #for OR operation using unique\n",
        "\n",
        "print(unique)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQLolesy4-yy",
        "outputId": "c19ea153-542d-42c5-a20a-e80ff5022c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Or java word occurs in the following Doc Ids\n",
            "[3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### web AND crawl"
      ],
      "metadata": {
        "id": "nQuZkTy46lE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"web AND crawl word occurs in the following position\")\n",
        "wb=[]\n",
        "first_tuple_elements_wb = [a_tuple[0] for a_tuple in inv_index.get(\"web\")]    #extracting doc ids from inverted index \n",
        "                                                                                    #dict value using get(keyword)\n",
        "\n",
        "for docid in first_tuple_elements_wb:\n",
        "  wb.append(docid)\n",
        "  \n",
        "crl=[]\n",
        "first_tuple_elements_crawl = [a_tuple[0] for a_tuple in inv_index.get(\"crawl\")]\n",
        "for docid in first_tuple_elements_crawl:\n",
        "  crl.append(docid)\n",
        "\n",
        "print(\"DOC IDs containing crawl and web are : \")\n",
        "def Intersection(wb, crl):                   #using intersection of list for AND operation\n",
        "    return set(wb).intersection(crl)\n",
        "print(Intersection(wb, crl))    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mK6CH7BzIDP",
        "outputId": "ed40a4a6-6ef5-413d-dca7-33d1ede2db47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "web AND crawl word occurs in the following position\n",
            "DOC IDs containing crawl and web are : \n",
            "{5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###not Selenium"
      ],
      "metadata": {
        "id": "6n2se64J6oXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docids = [1,2,3,4,5]\n",
        "first_tuple_elements_selenium = [a_tuple[0] for a_tuple in inv_index.get(\"selenium\")]\n",
        "print(\"DOC IDs not containing selenium are : \")\n",
        "for dc in docids:\n",
        "  if dc not in  first_tuple_elements_selenium:\n",
        "    print(dc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrNvd0C06kEZ",
        "outputId": "3722481c-65d9-492e-962f-7231be42cbcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DOC IDs not containing selenium are : \n",
            "4\n"
          ]
        }
      ]
    }
  ]
}