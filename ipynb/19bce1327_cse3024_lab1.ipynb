{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNo7TPQOMJid"
      },
      "source": [
        "**# Question 1**\n",
        "\n",
        "Given a root URL, e.g., `vit.ac.in`, Design a simple crawler using Python to return all pages that contains a string `admissions` from this site."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "DN2bdMFQMJit"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "lBrhlkM9MJiz"
      },
      "outputs": [],
      "source": [
        "root_URL = \"https://www.vit.ac.in/\"\n",
        "search_word = \"admissions\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8IE8o2MMJi1",
        "outputId": "8d8ef1c3-13ca-4674-a55b-edffc6047328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status of the response :  200\n"
          ]
        }
      ],
      "source": [
        "# Use the requests library to retrieve the web page of the root URL\n",
        "\n",
        "response = requests.get(root_URL)\n",
        "print(\"Status of the response : \", response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Oyh-o8YPMJi5"
      },
      "outputs": [],
      "source": [
        "# Use the Beautiful Soap library to parse the retrieved web page\n",
        "\n",
        "root_page = BeautifulSoup(response.content, 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yExlL25IMJi7",
        "outputId": "d1e6858d-fcc7-4277-b440-dbaf386a98e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://vit.ac.in/admissions/overview', 'https://vit.ac.in/admissions/overview', 'https://vit.ac.in/admissions/programmes-offered', 'https://vit.ac.in/admissions/research', 'https://vit.ac.in/admissions/research/Integrated_Ph.D', 'https://vit.ac.in/admissions/research/phd', 'https://vit.ac.in/admissions/international', 'https://vit.ac.in/admissions/international/overview', 'https://admissions.vit.ac.in/payment/freshers', 'https://admissions.vit.ac.in/pgapplication/', 'https://vit.ac.in/admissions/overview']\n"
          ]
        }
      ],
      "source": [
        "# Retrieve all the links to the sub-pages by retrieving all the `<a>` tags\n",
        "\n",
        "anchor_tags = root_page.find_all('a')\n",
        "\n",
        "result = []\n",
        "\n",
        "# Check if the word \"admission\" is present in each page, and if so then save its URL\n",
        "for anchor_tag in anchor_tags :\n",
        "    link = anchor_tag['href']\n",
        "    if re.search(search_word, link, re.IGNORECASE) :\n",
        "        result.append(link)\n",
        "print(result)        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCXhEGq-MJi9",
        "outputId": "4ca818b8-d61e-431e-f230-661978f1eb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The links in the root URL page which contains the word 'admissions' are :\n",
            "\t https://vit.ac.in/admissions/overview\n",
            "\t https://vit.ac.in/admissions/overview\n",
            "\t https://vit.ac.in/admissions/programmes-offered\n",
            "\t https://vit.ac.in/admissions/research\n",
            "\t https://vit.ac.in/admissions/research/Integrated_Ph.D\n",
            "\t https://vit.ac.in/admissions/research/phd\n",
            "\t https://vit.ac.in/admissions/international\n",
            "\t https://vit.ac.in/admissions/international/overview\n",
            "\t https://admissions.vit.ac.in/payment/freshers\n",
            "\t https://admissions.vit.ac.in/pgapplication/\n",
            "\t https://vit.ac.in/admissions/overview\n"
          ]
        }
      ],
      "source": [
        "print(\"The links in the root URL page which contains the word 'admissions' are :\")\n",
        "for url in result :\n",
        "    print(\"\\t\", url)\n",
        "\n",
        "with open('resultsq1.csv', mode='w', newline='') as csv_file:\n",
        "  csv_writer = csv.writer(csv_file,delimiter=\"\\t\")\n",
        "  for url in result:\n",
        "    csv_writer.writerow(url)    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2**\n",
        "Find documents that contain the word “admissions” and the word “international” within the URL “Vit.ac.in” using *Python*"
      ],
      "metadata": {
        "id": "DTgn2kIEEwTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_word2 = \"international\"\n",
        "result2 = []\n",
        "# Check if the words \"admission\" and \"international\" is present in each page, and if so then save its URL\n",
        "for anchor_tag in anchor_tags :\n",
        "    link = anchor_tag['href']\n",
        "    if re.search(search_word, link, re.IGNORECASE) and re.search(search_word2, link, re.IGNORECASE) :\n",
        "        result2.append(link)\n",
        "print(result2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA5nhmXCE2UK",
        "outputId": "8227f089-7694-43eb-e489-c2916e9ca983"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://vit.ac.in/admissions/international', 'https://vit.ac.in/admissions/international/overview']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 3**\n",
        "\t\n",
        "  Find documents that contain the word “Programme” but not the word “programming” within the URL “Vit.ac.in” using Python. (5 pages)\n"
      ],
      "metadata": {
        "id": "zF2BjHbFKQGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_word3='Programme'\n",
        "search_word4='programming'\n",
        "\n",
        "anchor_tags = root_page.find_all('a')\n",
        "result3 = []\n",
        "count=0\n",
        "while count < 5:\n",
        "  for link in anchor_tags:\n",
        "    if(re.search(search_word3,link.get('href'),re.IGNORECASE) and not(re.search(search_word4,link.get('href'),re.IGNORECASE))):\n",
        "        result3.append(link.get('href'))\n",
        "        count+=1\n",
        "        if count == 5:\n",
        "          break\n",
        "for doclink in result3:\n",
        "    print(doclink)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdyNyKzsKgbD",
        "outputId": "d6364c4a-bfaf-480d-e55e-487fd0c9dc35"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://vit.ac.in/programmes-offered-1\n",
            "https://vit.ac.in/programmes-offered-2021-22\n",
            "https://vit.ac.in/programmes-offered-2020-21\n",
            "https://vit.ac.in/admissions/programmes-offered\n",
            "https://vit.ac.in/programmes-offered-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4**\n",
        "Write a web crawler program which takes as input a url(Educational website) and a search key word and maximum number of pages (15-20 Pages)  to be searched and returns as output all the web pages it searched till it found the search word on a web page or return failure."
      ],
      "metadata": {
        "id": "FWbJlhKpP0LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#takingurl, key word and max limit of webpages to be serached as input\n",
        "url = input('Enter URL of the educational website : ')\n",
        "search_word5 = input('Search Key Word : ')\n",
        "maxpages = int(input('Enter maximum no of pages to be searched : '))\n",
        "#intializing pagecount and result list\n",
        "pagecount = 0\n",
        "result4 = []\n",
        "boolean = False  #initializing boolean flag\n",
        "\n",
        "# Use the requests library to retrieve the web page of the root URL,\n",
        "#Beautiful Soap library to parse the retrieved web page\n",
        "#Retrieve all the links to the sub-pages by retrieving all the `<a>` tags\n",
        "\n",
        "response = requests.get(url)\n",
        "root_page = BeautifulSoup(response.content, 'html.parser')\n",
        "anchor_tags = root_page.find_all('a')\n",
        "\n",
        "# using loop check anchor tags with href link and using regex search the links \n",
        "# having search word and change the flag value to True when found and append link\n",
        "# when pagecount reaches maxpage limit break the loop\n",
        "for link in anchor_tags:\n",
        "    if link.get('href')==None:\n",
        "        continue\n",
        "    elif(re.search(search_word5,link.get('href'),re.IGNORECASE)):\n",
        "        boolean=True\n",
        "        result4.append(link.get('href'))\n",
        "        pagecount=pagecount+1\n",
        "        break\n",
        "    elif(pagecount==maxpages):\n",
        "        break\n",
        "if boolean:\n",
        "    for ans in result4:\n",
        "        print(ans)\n",
        "else:\n",
        "    print('failure')  #when searchword is not found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmyTEYLgP-vT",
        "outputId": "a39bff46-2f82-48d8-fd1b-b2bbbc59e414"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter URL of the educational website : https://www.iiit.ac.in\n",
            "Search Key Word : Alumni\n",
            "Enter maximum no of pages to be searched : 19\n",
            "https://www.iiit.ac.in/community/alumni/give/\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "19bce1327_cse3024_lab1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}